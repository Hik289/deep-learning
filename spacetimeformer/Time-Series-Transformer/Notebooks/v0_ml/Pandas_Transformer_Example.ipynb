{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Transformer\n",
    "\n",
    "## Making Lags and Lead Features for Machine Learning\n",
    "\n",
    "### Lag data\n",
    "\n",
    "To train a supervised machine learning model, we can use lag data as part of feature engineering. A lag data is its piror time step's value. In this package, we can use Pandas_Time_Series_Panel_Dataset to make lag data with multiple piror time steps (window size). This example will first create a simple pandas frame and demonstrate how to create lag data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time_series_transform as tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create its lag data, we can use make_slide_window funciton. It has four parameters\n",
    "1. indexCol: time sereis column name, this parameter will be used for sorting the data frame before any manipulation\n",
    "2. windowSize: how many lags will be created \n",
    "3. colList: the target column names. if None is passing, all column except groupby column and index column will be trasformed\n",
    "4. groupby: category of the data\n",
    "\n",
    "This is a simple data frame with no category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1  x2\n",
      "0     1   1   6\n",
      "1     2   2   7\n",
      "2     3   3   8\n",
      "3     4   4   9\n",
      "4     5   5  10\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'time':[1,2,3,4,5],'x1':[1,2,3,4,5],'x2':[6,7,8,9,10]})\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1  x2  x1_lag1  x1_lag2\n",
      "0     1   1   6      NaN      NaN\n",
      "1     2   2   7      1.0      NaN\n",
      "2     3   3   8      2.0      1.0\n",
      "3     4   4   9      3.0      2.0\n",
      "4     5   5  10      4.0      3.0\n"
     ]
    }
   ],
   "source": [
    "time_panel = tst.Pandas_Time_Series_Panel_Dataset(data)\n",
    "print(time_panel.make_slide_window(\n",
    "    indexCol = 'time',\n",
    "    windowSize= 2,\n",
    "    colList= ['x1']\n",
    ")) \n",
    "# if colList is passed, only list item will be transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1  x2  x1_lag1  x1_lag2  x2_lag1  x2_lag2  x1_lag1_lag1  \\\n",
      "0     1   1   6      NaN      NaN      NaN      NaN           NaN   \n",
      "1     2   2   7      1.0      NaN      6.0      NaN           NaN   \n",
      "2     3   3   8      2.0      1.0      7.0      6.0           1.0   \n",
      "3     4   4   9      3.0      2.0      8.0      7.0           2.0   \n",
      "4     5   5  10      4.0      3.0      9.0      8.0           3.0   \n",
      "\n",
      "   x1_lag1_lag2  x1_lag2_lag1  x1_lag2_lag2  \n",
      "0           NaN           NaN           NaN  \n",
      "1           NaN           NaN           NaN  \n",
      "2           NaN           NaN           NaN  \n",
      "3           1.0           1.0           NaN  \n",
      "4           2.0           2.0           1.0  \n"
     ]
    }
   ],
   "source": [
    "time_panel = tst.Pandas_Time_Series_Panel_Dataset(data)\n",
    "print(time_panel.make_slide_window(\n",
    "    indexCol = 'time',\n",
    "    windowSize= 2,\n",
    "    colList= None\n",
    ")) \n",
    "# if None is passed, all column will be transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, this item could associated with different categories. To manipulate the data, we can either expand the window using expand_dataFrame_by_category to create multiple columns before making lag data or use groupby parameter inside of make_slide_window to produce lag data associate with its category.\n",
    "\n",
    "Note: expand_dataFrame_by_category and groupby parameter only support on category column. If you have multiple category column, you can concate each category into one new category before using this api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1  x2  category\n",
      "0     1   1   6         1\n",
      "1     2   2   7         1\n",
      "2     3   3   8         1\n",
      "3     4   4   9         1\n",
      "4     5   5  10         1\n",
      "5     1   1   6         2\n",
      "6     2   2   7         2\n",
      "7     3   3   8         2\n",
      "8     4   4   9         2\n",
      "9     5   5  10         2\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "    {'time':[1,2,3,4,5,1,2,3,4,5],\n",
    "     'x1':[1,2,3,4,5,1,2,3,4,5],\n",
    "     'x2':[6,7,8,9,10,6,7,8,9,10],\n",
    "     'category':[1,1,1,1,1,2,2,2,2,2]\n",
    "    })\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expand_dataFrame_by_category function will produce columns with feature_category columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1_1  x2_1  x1_2  x2_2\n",
      "0     1     1     6     1     6\n",
      "1     2     2     7     2     7\n",
      "2     3     3     8     3     8\n",
      "3     4     4     9     4     9\n",
      "4     5     5    10     5    10\n"
     ]
    }
   ],
   "source": [
    "time_panel = tst.Pandas_Time_Series_Panel_Dataset(data)\n",
    "print(time_panel.expand_dataFrame_by_category('time','category'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After expanding the column, we can safely make its lag data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1_1  x2_1  x1_2  x2_2  x1_1_lag1  x1_1_lag2  x2_1_lag1  x2_1_lag2  \\\n",
      "0     1     1     6     1     6        NaN        NaN        NaN        NaN   \n",
      "1     2     2     7     2     7        1.0        NaN        6.0        NaN   \n",
      "2     3     3     8     3     8        2.0        1.0        7.0        6.0   \n",
      "3     4     4     9     4     9        3.0        2.0        8.0        7.0   \n",
      "4     5     5    10     5    10        4.0        3.0        9.0        8.0   \n",
      "\n",
      "   x1_2_lag1  x1_2_lag2  x2_2_lag1  x2_2_lag2  \n",
      "0        NaN        NaN        NaN        NaN  \n",
      "1        1.0        NaN        6.0        NaN  \n",
      "2        2.0        1.0        7.0        6.0  \n",
      "3        3.0        2.0        8.0        7.0  \n",
      "4        4.0        3.0        9.0        8.0  \n"
     ]
    }
   ],
   "source": [
    "print(time_panel.make_slide_window(\n",
    "    indexCol = 'time',\n",
    "    windowSize= 2,\n",
    "    colList= None\n",
    ")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use groupby parameter in make_slide_window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1  x2  category  x1_lag1  x1_lag2  x2_lag1  x2_lag2\n",
      "0     1   1   6         1      NaN      NaN      NaN      NaN\n",
      "5     1   1   6         2      NaN      NaN      NaN      NaN\n",
      "1     2   2   7         1      1.0      NaN      6.0      NaN\n",
      "6     2   2   7         2      1.0      NaN      6.0      NaN\n",
      "2     3   3   8         1      2.0      1.0      7.0      6.0\n",
      "7     3   3   8         2      2.0      1.0      7.0      6.0\n",
      "3     4   4   9         1      3.0      2.0      8.0      7.0\n",
      "8     4   4   9         2      3.0      2.0      8.0      7.0\n",
      "4     5   5  10         1      4.0      3.0      9.0      8.0\n",
      "9     5   5  10         2      4.0      3.0      9.0      8.0\n"
     ]
    }
   ],
   "source": [
    "time_panel = tst.Pandas_Time_Series_Panel_Dataset(data)\n",
    "print(time_panel.make_slide_window(\n",
    "    indexCol = 'time',\n",
    "    windowSize= 2,\n",
    "    colList= None,\n",
    "    groupby = 'category'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Lead data\n",
    "\n",
    "Like making lag data, this class provides function to create lead data. Lead data is the the future time step value of the feature. In supervised learning, the target variable is usually associate with its lead value.\n",
    "\n",
    "To make lead data we can use make_lead_column function. In this function, there are four parameter\n",
    "1. indexCol: time sereis column name, this parameter will be used for sorting the data frame before any manipulation\n",
    "2. baseCol: the target column for transformation\n",
    "3. leadNum: lead step number\n",
    "4. groupby: dealing with category column\n",
    "\n",
    "Note: Lead function will only create on lead column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1  x2\n",
      "0     1   1   6\n",
      "1     2   2   7\n",
      "2     3   3   8\n",
      "3     4   4   9\n",
      "4     5   5  10\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'time':[1,2,3,4,5],'x1':[1,2,3,4,5],'x2':[6,7,8,9,10]})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   time  x1  x2  x1_lead1\n",
       "4     5   5  10       NaN\n",
       "3     4   4   9       5.0\n",
       "2     3   3   8       4.0\n",
       "1     2   2   7       3.0\n",
       "0     1   1   6       2.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_panel = tst.Pandas_Time_Series_Panel_Dataset(data)\n",
    "time_panel.make_lead_column('time','x1',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  x1  x2  category\n",
      "0     1   1   6         1\n",
      "1     2   2   7         1\n",
      "2     3   3   8         1\n",
      "3     4   4   9         1\n",
      "4     5   5  10         1\n",
      "5     1   1   6         2\n",
      "6     2   2   7         2\n",
      "7     3   3   8         2\n",
      "8     4   4   9         2\n",
      "9     5   5  10         2\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "    {'time':[1,2,3,4,5,1,2,3,4,5],\n",
    "     'x1':[1,2,3,4,5,1,2,3,4,5],\n",
    "     'x2':[6,7,8,9,10,6,7,8,9,10],\n",
    "     'category':[1,1,1,1,1,2,2,2,2,2]\n",
    "    })\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   time  x1  x2  category  x1_lead1\n",
       "4     5   5  10         1       NaN\n",
       "9     5   5  10         2       NaN\n",
       "3     4   4   9         1       5.0\n",
       "8     4   4   9         2       5.0\n",
       "2     3   3   8         1       4.0\n",
       "7     3   3   8         2       4.0\n",
       "1     2   2   7         1       3.0\n",
       "6     2   2   7         2       3.0\n",
       "0     1   1   6         1       2.0\n",
       "5     1   1   6         2       2.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_panel = tst.Pandas_Time_Series_Panel_Dataset(data)\n",
    "time_panel.make_lead_column('time','x1',1,'category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Tensor Data for Deep Learning\n",
    "\n",
    "For deep learning model, especially for cnn or rnn, tensor can be very useful. Using Pandas_Time_Series_Tensor_Dataset, we can easily create different types of tensor.\n",
    "\n",
    "1. sequence: make lag data given a window size\n",
    "2. label: make lead data with one step forward\n",
    "3. category: make category variable corrsponding to its sequence with given window size\n",
    "4. same: return same data list\n",
    "\n",
    "\n",
    "### Expand DataFrame\n",
    "\n",
    "To use this api, it is necessary to expand the data by its date. To achieve, you can simply use expand_dataFrame_by_date function.\n",
    "\n",
    "Note, if newIX is True, all time series will be label from 1 through time series number. And, ixDict attribute will be saved in the class object. This attribute can be used to trace the naming before and after new index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If byCategory is True, the row will still group by category. The columns are only expand by time data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  time  x1  x2  category\n",
      "0    a   1   6         1\n",
      "1    b   2   7         1\n",
      "2    c   3   8         1\n",
      "3    d   4   9         1\n",
      "4    e   5  10         1\n",
      "5    a   1   6         2\n",
      "6    b   2   7         2\n",
      "7    c   3   8         2\n",
      "8    d   4   9         2\n",
      "9    e   5  10         2\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "    {'time':['a','b','c','d','e','a','b','c','d','e'],\n",
    "     'x1':[1,2,3,4,5,1,2,3,4,5],\n",
    "     'x2':[6,7,8,9,10,6,7,8,9,10],\n",
    "     'category':[1,1,1,1,1,2,2,2,2,2]\n",
    "    })\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, if it is False, it will be fully expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5}\n",
      "          x1_1  x1_2  x1_3  x1_4  x1_5  x2_1  x2_2  x2_3  x2_4  x2_5\n",
      "category                                                            \n",
      "1            1     2     3     4     5     6     7     8     9    10\n",
      "2            1     2     3     4     5     6     7     8     9    10\n"
     ]
    }
   ],
   "source": [
    "tensor_transform = tst.Pandas_Time_Series_Tensor_Dataset(data)\n",
    "tensor_transform.expand_dataFrame_by_date('category','time',newIX = True,byCategory=True)\n",
    "print(tensor_transform.ixDict)\n",
    "print(tensor_transform.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5}\n",
      "   1_x1_1  1_x1_2  1_x1_3  1_x1_4  1_x1_5  1_x2_1  1_x2_2  1_x2_3  1_x2_4  \\\n",
      "0       1       2       3       4       5       6       7       8       9   \n",
      "\n",
      "   1_x2_5  2_x1_1  2_x1_2  2_x1_3  2_x1_4  2_x1_5  2_x2_1  2_x2_2  2_x2_3  \\\n",
      "0      10       1       2       3       4       5       6       7       8   \n",
      "\n",
      "   2_x2_4  2_x2_5  \n",
      "0       9      10  \n"
     ]
    }
   ],
   "source": [
    "tensor_transform = tst.Pandas_Time_Series_Tensor_Dataset(data)\n",
    "ixDict = tensor_transform.expand_dataFrame_by_date('category','time',byCategory=False)\n",
    "print(tensor_transform.ixDict)\n",
    "print(tensor_transform.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After expand the data frame, we have to setup up its configuration. This can be done by using set_config function. Its parameter include\n",
    "1. name: output variable name\n",
    "2. colNames: column list for transformation\n",
    "3. tensorType: transformation type {'sequence','category','label'}\n",
    "4. sequence_stack: whether to stack the output with other transformation\n",
    "5. isResponseVar: whether to ouput the variable in the target variable\n",
    "6. windowSize: grouping size\n",
    "7. seqSize: this parameter is only used for category transformation. It should be the total number of time sequence\n",
    "8. outType: output data type, and it should be numpy data type\n",
    "\n",
    "### Lag Data\n",
    "Here we use x1 variable associate with its category and time to make lag features. To get the transformation, we can use make_data_generator function to get an generator object. The generator will generate the manipulation of each row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x1': array([[[1],\n",
      "        [2]],\n",
      "\n",
      "       [[2],\n",
      "        [3]],\n",
      "\n",
      "       [[3],\n",
      "        [4]]])}, None)\n",
      "Shape:(3, 2, 1)\n",
      "({'x1': array([[[1],\n",
      "        [2]],\n",
      "\n",
      "       [[2],\n",
      "        [3]],\n",
      "\n",
      "       [[3],\n",
      "        [4]]])}, None)\n",
      "Shape:(3, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "tensor_transform = tst.Pandas_Time_Series_Tensor_Dataset(data)\n",
    "ixDict = tensor_transform.expand_dataFrame_by_date('category','time',byCategory=True) # demo not expand by category\n",
    "tensor_transform.set_config(\n",
    "    name='x1',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='sequence',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "gen = tensor_transform.make_data_generator()\n",
    "for i in gen:\n",
    "    print(i)\n",
    "    print(f\"Shape:{str(i[0]['x1'].shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lead Data\n",
    "\n",
    "Since the label function will always produce one step forward list, we can use it to create response variable.\n",
    "\n",
    "This is one step forward data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = tst.Pandas_Time_Series_Tensor_Dataset(data)\n",
    "ixDict = tensor_transform.expand_dataFrame_by_date('category','time',byCategory=False) # demo expanded by category\n",
    "tensor_transform.set_config(\n",
    "    name='x_lead1',\n",
    "    colNames=['1_x1_1','1_x1_2','1_x1_3','1_x1_4','1_x1_5'],\n",
    "    tensorType='label',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x_lead1': array([3, 4, 5])}, None)\n",
      "Shape:(3,)\n"
     ]
    }
   ],
   "source": [
    "gen = tensor_transform.make_data_generator()\n",
    "for i in gen:\n",
    "    print(i)\n",
    "    print(f\"Shape:{str(i[0]['x_lead1'].shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data\n",
    "\n",
    "This is type of tensor is designed for making categorical data matching with sequence type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = tst.Pandas_Time_Series_Tensor_Dataset(data)\n",
    "ixDict = tensor_transform.expand_dataFrame_by_date('category','time',byCategory=True)\n",
    "tensor_transform.set_config(\n",
    "    name='x_category',\n",
    "    colNames=['x1_1'],\n",
    "    tensorType='category',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x_category': array([[1],\n",
      "       [1],\n",
      "       [1]])}, None)\n",
      "Shape:(3, 1)\n",
      "({'x_category': array([[1],\n",
      "       [1],\n",
      "       [1]])}, None)\n",
      "Shape:(3, 1)\n"
     ]
    }
   ],
   "source": [
    "gen = tensor_transform.make_data_generator()\n",
    "for i in gen:\n",
    "    print(i)\n",
    "    print(f\"Shape:{str(i[0]['x_category'].shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same Data\n",
    "\n",
    "To make more complicated manipulation, the data can be first pre-processed by Pandas_Time_Series_Panel_Dataset.\n",
    "Subsequently, it can be processed by Pandas_Time_Series_Tensor_Dataset. Same data will return the same array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = tst.Pandas_Time_Series_Tensor_Dataset(data)\n",
    "ixDict = tensor_transform.expand_dataFrame_by_date('category','time',byCategory=True)\n",
    "tensor_transform.set_config(\n",
    "    name='x_same',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='same',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x_same': array([1, 2, 3, 4, 5])}, None)\n",
      "Shape:(5,)\n",
      "({'x_same': array([1, 2, 3, 4, 5])}, None)\n",
      "Shape:(5,)\n"
     ]
    }
   ],
   "source": [
    "gen = tensor_transform.make_data_generator()\n",
    "for i in gen:\n",
    "    print(i)\n",
    "    print(f\"Shape:{str(i[0]['x_same'].shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Data and Target Variable\n",
    "\n",
    "Sometimes, we want to stack multiple sequence together. Using sequence_stack parameter, we can stack data together. The shape of the output data will be (batch size, window size, feature number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = tst.Pandas_Time_Series_Tensor_Dataset(data)\n",
    "ixDict = tensor_transform.expand_dataFrame_by_date('category','time',byCategory=True)\n",
    "tensor_transform.set_config(\n",
    "    name='x_same',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='same',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "tensor_transform.set_config(\n",
    "    name='x_same2',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='same',\n",
    "    sequence_stack='x_same',\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "tensor_transform.set_config(\n",
    "    name='x_sequence',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='sequence',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "tensor_transform.set_config(\n",
    "    name='x_sequence_2',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='sequence',\n",
    "    sequence_stack='x_sequence',\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "tensor_transform.set_config(\n",
    "    name='y',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='label',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=True,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x_same': array([[1, 1],\n",
      "       [2, 2],\n",
      "       [3, 3],\n",
      "       [4, 4],\n",
      "       [5, 5]]), 'x_sequence': array([[[1, 1],\n",
      "        [2, 2]],\n",
      "\n",
      "       [[2, 2],\n",
      "        [3, 3]],\n",
      "\n",
      "       [[3, 3],\n",
      "        [4, 4]]])}, array([3, 4, 5]))\n"
     ]
    }
   ],
   "source": [
    "gen = tensor_transform.make_data_generator()\n",
    "tmp = next(gen)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Adopter\n",
    "\n",
    "## TFReford Writer\n",
    "\n",
    "Time series tensor can easily getting very big and computational expensive. Hence, time_series_transformer provides an API to create and read TFRecord. Using TFRecord Writer will create two files.\n",
    "1. TFRecord data\n",
    "2. A metadata used for TFRecord Reader (can be pickled)\n",
    "\n",
    "To create the tfRecord file, you have to use write_tfRecord function. While to create read MetaData you can use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time_series_transform.transform_core_api.tensorflow_adopter import TFRecord_Reader,TFRecord_Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    {'time':['a','b','c','d','e','a','b','c','d','e'],\n",
    "     'x1':[1,2,3,4,5,1,2,3,4,5],\n",
    "     'x2':[6,7,8,9,10,6,7,8,9,10],\n",
    "     'category':[1,1,1,1,1,2,2,2,2,2]\n",
    "    })\n",
    "tensor_transform = tst.Pandas_Time_Series_Tensor_Dataset(data)\n",
    "ixDict = tensor_transform.expand_dataFrame_by_date('category','time',byCategory=True)\n",
    "tensor_transform.set_config(\n",
    "    name='x_same',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='same',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "tensor_transform.set_config(\n",
    "    name='x_same2',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='same',\n",
    "    sequence_stack='x_same',\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "tensor_transform.set_config(\n",
    "    name='x_sequence',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='sequence',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "tensor_transform.set_config(\n",
    "    name='x_sequence_2',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='sequence',\n",
    "    sequence_stack='x_sequence',\n",
    "    isResponseVar=False,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "tensor_transform.set_config(\n",
    "    name='y',\n",
    "    colNames=['x1_1','x1_2','x1_3','x1_4','x1_5'],\n",
    "    tensorType='label',\n",
    "    sequence_stack=None,\n",
    "    isResponseVar=True,\n",
    "    windowSize=2,\n",
    "    seqSize=5,\n",
    "    outType=np.float\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = TFRecord_Writer('./tmp.tfRecor')\n",
    "tr.write_tfRecord(tensor_transform.make_data_generator())\n",
    "metaData = tr.get_tfRecord_dtype('./meta.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord Reader\n",
    "\n",
    "To make tfRecord into tensorflow dataset, you can use the TFReader API with the metadata created by TFRecord_Writer.\n",
    "To create the dataset object, you can use make_tfDataset function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = TFRecord_Reader('./tmp.tfRecor',metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tw.make_tfDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_same': <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
      "array([[1., 1.],\n",
      "       [2., 2.],\n",
      "       [3., 3.],\n",
      "       [4., 4.],\n",
      "       [5., 5.]], dtype=float32)>, 'x_sequence': <tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n",
      "array([[[1., 1.],\n",
      "        [2., 2.]],\n",
      "\n",
      "       [[2., 2.],\n",
      "        [3., 3.]],\n",
      "\n",
      "       [[3., 3.],\n",
      "        [4., 4.]]], dtype=float32)>, 'label': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([3., 4., 5.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for i in tf_dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
